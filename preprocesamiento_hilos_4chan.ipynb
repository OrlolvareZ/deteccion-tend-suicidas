{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fBq1jPuAhr0Y"
   },
   "source": [
    "# Preprocesamiento de hilos en 4chan\n",
    "\n",
    "En este cuaderno se procesan las publicaciones de 4chan, obtenidas a través de [web scrapping](./Scraper-4chan). Estas publicaciones pertenecen a múltiples [hilos que son considerados pertinentes]() para el objetivo de la investigación, ya sea por su idiosincrática nocividad en el uso del lenguaje, por la expresión misma de ideaciones/intenciones suicidas, o por contener sugerencias para llevar a cabo el suicidio.\n",
    "\n",
    "El objetivo de este cuaderno es retirar caracteres inútiles, transformar el contenido de cada publicación a minúsculas y eliminar los saltos de lí­nea en cada publicación. Además, es posible emplear una lista de palabras objetivo y localizar las publicaciones que contengan alguna de ellas.\n",
    "\n",
    "Para esta tarea se utilizará la librería de `pandas`, pues su parser de archivos `.csv` admite por defecto el uso de saltos de lí­nea en los campos de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TwNbWjYBdYmG"
   },
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import pandas\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NPgNh-OHgOlo"
   },
   "source": [
    "A raíz de que se han consultado (y se consultarán) múltiples hilos, este script lee todas las publicaciones de los hilos y realiza múltiples operaciones sobre ellos.\n",
    "\n",
    "A su vez, se crea una lista de nombres de archivos ya procesados, para excluirlos de la lectura cuando se trabaje en sesiones posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yCRhJJVujCpw"
   },
   "outputs": [],
   "source": [
    "# Función para encontrar archivos\n",
    "\n",
    "def encontrar_archivos(patron: str, ruta_base: str, lista_ex: list, verbose: bool = False):\n",
    "\n",
    "    archivos = []\n",
    "    index = 1\n",
    "\n",
    "    for root, _, files in os.walk(ruta_base):\n",
    "\n",
    "        for name in files:\n",
    "\n",
    "            if fnmatch.fnmatch(name, patron) and name not in lista_ex:\n",
    "                archivos.append(os.path.join(root, name))\n",
    "                if verbose:\n",
    "                    print(f'Archivo #{index}: {name}')\n",
    "                    index += 1\n",
    "\n",
    "    return archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3-RCHV0dpx25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahorcarme_complete.csv',\n",
       " 'colgarme_complete.csv',\n",
       " '',\n",
       " '1436774 - comments & replies.csv',\n",
       " '17913796 - comments & replies.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos los archivos ya procesados desde un archivo de texto\n",
    "archivos_procesados = []\n",
    "\n",
    "with open('./datos/lista_procesados.txt', 'r') as archivo: \n",
    "    for linea in archivo:\n",
    "        archivos_procesados.append(linea.strip())\n",
    "\n",
    "archivos_de_la_sesion = []\n",
    "archivos_procesados[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4P4rzornxiM",
    "outputId": "d1cb428b-11ff-4dc2-d1ff-b80332e2c8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo #1: Thread-124205675-Welcome to pol - Politically Incorrect.csv\n",
      "Archivo #2: Thread-259848258-Not Subject.csv\n",
      "Archivo #3: Thread-434008998-Humour Thread.csv\n",
      "Archivo #4: Thread-434012818-Dear White People,.csv\n",
      "Archivo #5: Thread-434014765-auspol aussie heros edition.csv\n",
      "Archivo #6: Thread-434016208-Juden Peterstein.csv\n",
      "Archivo #7: Thread-434021201-Not Subject.csv\n",
      "Archivo #8: Thread-434024619-You will accept a black friend into your group and you will be happy..csv\n",
      "Archivo #9: Thread-434026836-WE WON, YOU LOST!!.csv\n",
      "Archivo #10: Thread-434027893-Not Subject.csv\n",
      "Archivo #11: Thread-434028339-Cucks vs Nazis.csv\n",
      "Archivo #12: Thread-434028622-Chuck Schumer just declared war against SCOTUS.csv\n",
      "Archivo #13: Thread-434029177-If you eat out more than you cook at home, then you need to lower your tone when you talk to me.csv\n",
      "Archivo #14: Thread-434029427-Britpol Queen Anne Edition.csv\n",
      "Archivo #15: Thread-434030718-MEN ARE NOT DATING ANYMORE.csv\n",
      "Archivo #16: Thread-434031086-Not Subject.csv\n",
      "Archivo #17: Thread-434032332-Not Subject.csv\n",
      "Archivo #18: Thread-434033780-Not Subject.csv\n",
      "Archivo #19: Thread-434033994-chug - Comfy Happening in Ukraine General #11789.csv\n",
      "Archivo #20: Thread-434034359-uhg - Ukraine Happening General #10143.csv\n",
      "Archivo #21: Thread-434034573-Not Subject.csv\n",
      "Archivo #22: Thread-434035448-Not Subject.csv\n",
      "Archivo #23: Thread-434035833-Garth Brooks fans are you alright.csv\n",
      "Archivo #24: Thread-434036433-Not Subject.csv\n",
      "Archivo #25: Thread-434037469-Not Subject.csv\n",
      "Archivo #26: Thread-434037491-i refuse to believe that anyone could be this stupid.csv\n",
      "Archivo #27: Thread-434037495-Not Subject.csv\n",
      "Archivo #28: Thread-434037742-Kek. Israel..csv\n",
      "Archivo #29: Thread-434037999-A reminder.csv\n",
      "Archivo #30: Thread-434038234-HAPPENING! ICELAND VOLCANO ERUPTION!!!.csv\n"
     ]
    }
   ],
   "source": [
    "rutas_archivos = []\n",
    "rutas_base = [\n",
    "    './datos/hilos_4chan',\n",
    "]\n",
    "\n",
    "for ruta in rutas_base:\n",
    "    rutas_archivos.extend(\n",
    "        encontrar_archivos(\n",
    "            patron='*.csv',\n",
    "            ruta_base=ruta,\n",
    "            lista_ex=archivos_procesados,\n",
    "            verbose=True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s1SG0Yquxmfj"
   },
   "source": [
    "Los archivos contienen saltos de línea dentro de los campos, y las respuestas a un comentario raíz tienen el prefijo \"(REPLY) >>\", seguido del número del usuario. Esto se eliminará de las publicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "XkDtJOpN7E70"
   },
   "outputs": [],
   "source": [
    "def pre_procesar_dataset(dataset: pandas.DataFrame):\n",
    "\n",
    "    # Se eliminan los saltos de línea y los nombres de usuario en las publicaciones/respuestas\n",
    "    dataset['comment/reply'] = dataset['comment/reply'].str.replace(r'\\n|\\r', ' ', regex=True)\n",
    "    dataset['comment/reply'] = dataset['comment/reply'].str.replace(\n",
    "        '((\\(REPLY\\))?\\s>>.{8})|>', '', regex=True)\n",
    "    dataset['comment/reply'] = dataset['comment/reply'].str.lstrip()\n",
    "    # Se retiran las columnas que no se usarán\n",
    "    columnas = [\n",
    "        'post_id',\n",
    "        'subject',\n",
    "        'name',\n",
    "        'Name',\n",
    "        'is_op?',\n",
    "    ]\n",
    "    dataset.drop(columns=columnas, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Se renombran las columnas -> Esta adecuación se hace para darles un formato similar a los dataframes de Twitter,\n",
    "    # para que en algún momento sean más sencillos de procesar bajo el mismo conjunto de instrucciones\n",
    "    dataset.rename(\n",
    "        columns={\n",
    "            'date_time': 'Date',\n",
    "            'comment/reply': 'Content',\n",
    "            'url': 'URL'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # Se eliminan las filas que no tienen contenido\n",
    "    dataset.dropna(subset=['Content'], inplace=True)\n",
    "\n",
    "def obtener_hilo_desde_ruta(ruta: str):\n",
    "    # Para conocer el hilo, se obtiene el nombre del directorio padre de la ruta\n",
    "    nombre_hilo = os.path.basename(os.path.dirname(ruta))\n",
    "    # Se eliminan los números y el guión del nombre del hilo\n",
    "    nombre_hilo = re.sub(r'^([0-9]*\\s-\\s)|^(Thread-[0-9]*-)', '', nombre_hilo, )\n",
    "\n",
    "    return nombre_hilo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5E3QWpETr6um",
    "outputId": "371aad1a-a075-4931-8da7-28063abcf955"
   },
   "outputs": [],
   "source": [
    "# Se leen los archivos .csv encontrados\n",
    "datasets = []\n",
    "\n",
    "for ruta in rutas_archivos:\n",
    "\n",
    "    dataset = pandas.read_csv(ruta)\n",
    "    pre_procesar_dataset(dataset)\n",
    "\n",
    "    datasets.append(\n",
    "        {\n",
    "            \"hilo\": obtener_hilo_desde_ruta(ruta),\n",
    "            \"datos\": dataset,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZVwQ2mgxeeF5",
    "outputId": "2d03d619-dbef-431b-c860-2c8436516a58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jul-10-2023, 15:32:21</td>\n",
       "      <td>new usage figures show the number of calls mad...</td>\n",
       "      <td>http://boards.4chan.org/pol/thread/434014765/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jul-10-2023, 15:35:52</td>\n",
       "      <td>Based FEDPOL thread faggot kill yourself</td>\n",
       "      <td>http://boards.4chan.org/pol/thread/434014765/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jul-10-2023, 15:38:46</td>\n",
       "      <td>give it up mate cant you just tell me your bre...</td>\n",
       "      <td>http://boards.4chan.org/pol/thread/434014765/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jul-10-2023, 15:40:10</td>\n",
       "      <td>FAGGITS</td>\n",
       "      <td>http://boards.4chan.org/pol/thread/434014765/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jul-10-2023, 15:44:23</td>\n",
       "      <td>enough about you and your dad</td>\n",
       "      <td>http://boards.4chan.org/pol/thread/434014765/a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date                                            Content  \\\n",
       "0  Jul-10-2023, 15:32:21  new usage figures show the number of calls mad...   \n",
       "1  Jul-10-2023, 15:35:52           Based FEDPOL thread faggot kill yourself   \n",
       "2  Jul-10-2023, 15:38:46  give it up mate cant you just tell me your bre...   \n",
       "3  Jul-10-2023, 15:40:10                                            FAGGITS   \n",
       "4  Jul-10-2023, 15:44:23                      enough about you and your dad   \n",
       "\n",
       "                                                 URL  \n",
       "0  http://boards.4chan.org/pol/thread/434014765/a...  \n",
       "1  http://boards.4chan.org/pol/thread/434014765/a...  \n",
       "2  http://boards.4chan.org/pol/thread/434014765/a...  \n",
       "3  http://boards.4chan.org/pol/thread/434014765/a...  \n",
       "4  http://boards.4chan.org/pol/thread/434014765/a...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observemos un ejemplo\n",
    "datasets[4]['datos'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos una columna con el nombre del hilo\n",
    "for dataset in datasets:\n",
    "    dataset['datos']['Thread'] = dataset['hilo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>URL</th>\n",
       "      <th>Thread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jul-10-2023, 15:32:21</td>\n",
       "      <td>new usage figures show the number of calls mad...</td>\n",
       "      <td>http://boards.4chan.org/pol/thread/434014765/a...</td>\n",
       "      <td>auspol aussie heros edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jul-10-2023, 15:35:52</td>\n",
       "      <td>Based FEDPOL thread faggot kill yourself</td>\n",
       "      <td>http://boards.4chan.org/pol/thread/434014765/a...</td>\n",
       "      <td>auspol aussie heros edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jul-10-2023, 15:38:46</td>\n",
       "      <td>give it up mate cant you just tell me your bre...</td>\n",
       "      <td>http://boards.4chan.org/pol/thread/434014765/a...</td>\n",
       "      <td>auspol aussie heros edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jul-10-2023, 15:40:10</td>\n",
       "      <td>FAGGITS</td>\n",
       "      <td>http://boards.4chan.org/pol/thread/434014765/a...</td>\n",
       "      <td>auspol aussie heros edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jul-10-2023, 15:44:23</td>\n",
       "      <td>enough about you and your dad</td>\n",
       "      <td>http://boards.4chan.org/pol/thread/434014765/a...</td>\n",
       "      <td>auspol aussie heros edition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date                                            Content  \\\n",
       "0  Jul-10-2023, 15:32:21  new usage figures show the number of calls mad...   \n",
       "1  Jul-10-2023, 15:35:52           Based FEDPOL thread faggot kill yourself   \n",
       "2  Jul-10-2023, 15:38:46  give it up mate cant you just tell me your bre...   \n",
       "3  Jul-10-2023, 15:40:10                                            FAGGITS   \n",
       "4  Jul-10-2023, 15:44:23                      enough about you and your dad   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  http://boards.4chan.org/pol/thread/434014765/a...   \n",
       "1  http://boards.4chan.org/pol/thread/434014765/a...   \n",
       "2  http://boards.4chan.org/pol/thread/434014765/a...   \n",
       "3  http://boards.4chan.org/pol/thread/434014765/a...   \n",
       "4  http://boards.4chan.org/pol/thread/434014765/a...   \n",
       "\n",
       "                        Thread  \n",
       "0  auspol aussie heros edition  \n",
       "1  auspol aussie heros edition  \n",
       "2  auspol aussie heros edition  \n",
       "3  auspol aussie heros edition  \n",
       "4  auspol aussie heros edition  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[4]['datos'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "un1Gfb1wX0_M"
   },
   "source": [
    "Una vez preparados los datos, podemos guardar una copia de ellos para su futuro análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "uTOhcKLz6wJ8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta creada: ./datos_limpios/4chan\n"
     ]
    }
   ],
   "source": [
    "# Creamos la ruta donde se guardarán los archivos\n",
    "ruta_guardado = \"./datos_limpios/4chan\"\n",
    "sufijo = \"_cleaned.csv\"\n",
    "\n",
    "os.makedirs(ruta_guardado, exist_ok=True)\n",
    "print(f'Ruta creada: {ruta_guardado}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_ in datasets:\n",
    "    hilo = dict_['hilo']\n",
    "    dataset = dict_['datos']\n",
    "    nombre_guardado_full = f\"{ruta_guardado}/{hilo}{sufijo}\"\n",
    "    dataset.to_csv(nombre_guardado_full, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que agregamos información del hilo al que pertenece, podemos juntar todas las publicaciones en un solo archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = pandas.concat([dict_['datos'] for dict_ in datasets])\n",
    "\n",
    "ruta_dataset_full = f\"{ruta_guardado}/dataset_4chan.csv\"\n",
    "\n",
    "# Comprobamos si el archivo ya existe. Si no existe, incluiremos la fila de encabezado\n",
    "dataset_full_existe = True if os.path.isfile(ruta_dataset_full) else False\n",
    "incluir_encabezado = False if dataset_full_existe else True\n",
    "\n",
    "# Siempre se anexan los datos nuevos al archivo\n",
    "dataset_full.to_csv(ruta_dataset_full, index=False, header=incluir_encabezado, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlF01iyjZtO9"
   },
   "source": [
    "Además, podemos leer una serie de palabras relevantes de un archivo, para después obtener únicamente publicaciones que las contienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "rrySYzLKZkqc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algunas de las palabras son:  ['suicide', 'suicidal', 'suic', 'self-harm', 'self-injury']\n"
     ]
    }
   ],
   "source": [
    "ruta_archivo_palabras = './datos_p_filtrar/palabras_objetivo.txt'\n",
    "\n",
    "with open(ruta_archivo_palabras, 'r') as archivo:\n",
    "    palabras = archivo.readlines()\n",
    "    palabras = [palabra.replace('\\n', '') for palabra in palabras]\n",
    "    print(\"Algunas de las palabras son: \", palabras[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos el dataset completo y recuperamos las publicaciones que contengan las palabras objetivo\n",
    "\n",
    "def filtrar_dataset_sesion(dataset: pandas.DataFrame, palabras: list):\n",
    "\n",
    "    # Quitamos las filas que no tienen contenido\n",
    "    dataset.dropna(subset=['Content'], inplace=True)\n",
    "\n",
    "    # Se crea una expresión regular que busca las palabras objetivo\n",
    "    regex = '|'.join(palabras)\n",
    "\n",
    "    print(regex)\n",
    "\n",
    "    # Se filtra el dataset\n",
    "    dataset_filtrado = dataset[\n",
    "        dataset['Content'].str.contains(regex, case=False, regex=True)\n",
    "    ]\n",
    "\n",
    "    return dataset_filtrado\n",
    "\n",
    "def filtrar_dataset_completo(ruta_dataset: str, palabras: list):\n",
    "\n",
    "    # Se leen los datos\n",
    "    dataset = pandas.read_csv(ruta_dataset)\n",
    "\n",
    "    # Se filtra el dataset\n",
    "    dataset_filtrado = filtrar_dataset_sesion(dataset, palabras)\n",
    "    return dataset_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suicide|suicidal|suic|self-harm|self-injury|self harm|self injury|hang myself|hung myself|kill myself|kills myself|killed myself|take my life|takes my life|want to die|wanted to die|wants to die|want death|wants death|wanted death|to be dead\n"
     ]
    }
   ],
   "source": [
    "# Mantenemos las filas que contengan las palabras objetivo\n",
    "\n",
    "# Descomentar esta línea si se trabajará con el dataset en memoria\n",
    "# dataset_full_filtrado = filtrar_dataset_sesion(dataset_full, palabras)\n",
    "\n",
    "# Descomentar estas líneas si se trabajará con el dataset completo\n",
    "dataset_full_ruta = pandas.read_csv(f\"{ruta_guardado}/dataset_4chan.csv\")\n",
    "dataset_full_filtrado = filtrar_dataset_completo(ruta_dataset_full, palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>URL</th>\n",
       "      <th>Thread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Jun-23-2023, 05:19:17</td>\n",
       "      <td>i am a BIG BLACK COCK BVLL  now go commit suic...</td>\n",
       "      <td>http://boards.4chan.org/bant/thread/17918614/b...</td>\n",
       "      <td>_bant__AI_Waifus_General__121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Jun-23-2023, 05:27:10</td>\n",
       "      <td>I won now go livestream your suicide</td>\n",
       "      <td>http://boards.4chan.org/bant/thread/17918614/b...</td>\n",
       "      <td>_bant__AI_Waifus_General__121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Jun-23-2023, 08:01:39</td>\n",
       "      <td>Gladly not white but my brother is and he talk...</td>\n",
       "      <td>http://boards.4chan.org/bant/thread/17928132/m...</td>\n",
       "      <td>manlet_pajeets_stealing_Polish_women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>Jun-08-2023, 20:37:00</td>\n",
       "      <td>I went to Tokyo when I was 17 in the summer of...</td>\n",
       "      <td>http://boards.4chan.org/trv/thread/2478234/why...</td>\n",
       "      <td>No Subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>Jan-17-2023, 02:36:50</td>\n",
       "      <td>Ultimately, ending slavery is a moralfag white...</td>\n",
       "      <td>http://boards.4chan.org/e/thread/2669577/slave...</td>\n",
       "      <td>Slaves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "383   Jun-23-2023, 05:19:17   \n",
       "387   Jun-23-2023, 05:27:10   \n",
       "505   Jun-23-2023, 08:01:39   \n",
       "934   Jun-08-2023, 20:37:00   \n",
       "1802  Jan-17-2023, 02:36:50   \n",
       "\n",
       "                                                Content  \\\n",
       "383   i am a BIG BLACK COCK BVLL  now go commit suic...   \n",
       "387                I won now go livestream your suicide   \n",
       "505   Gladly not white but my brother is and he talk...   \n",
       "934   I went to Tokyo when I was 17 in the summer of...   \n",
       "1802  Ultimately, ending slavery is a moralfag white...   \n",
       "\n",
       "                                                    URL  \\\n",
       "383   http://boards.4chan.org/bant/thread/17918614/b...   \n",
       "387   http://boards.4chan.org/bant/thread/17918614/b...   \n",
       "505   http://boards.4chan.org/bant/thread/17928132/m...   \n",
       "934   http://boards.4chan.org/trv/thread/2478234/why...   \n",
       "1802  http://boards.4chan.org/e/thread/2669577/slave...   \n",
       "\n",
       "                                    Thread  \n",
       "383          _bant__AI_Waifus_General__121  \n",
       "387          _bant__AI_Waifus_General__121  \n",
       "505   manlet_pajeets_stealing_Polish_women  \n",
       "934                             No Subject  \n",
       "1802                                Slaves  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_full_filtrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribimos el dataset filtrado, incluyendo el encabezado o no según corresponda\n",
    "\n",
    "# Descomentar esta línea si se trabajará con el dataset en memoria\n",
    "# modo = 'a'\n",
    "# incluir_encabezado = False\n",
    "# Descomentar estas líneas si se trabajará con el dataset completo\n",
    "modo = 'w'\n",
    "incluir_encabezado = True\n",
    "\n",
    "dataset_full_filtrado.to_csv(f\"{ruta_guardado}/dataset_4chan_keywords_only.csv\", index=False, mode=modo, header=incluir_encabezado)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para posteriores análisis, podemos decidir guardar los archivos procesados en la lista, para indicar que terminamos de correrlos por el pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anexamos los archivos procesados en esta sesión a la lista de archivos procesados\n",
    "\n",
    "with open('./datos/lista_procesados.txt', 'a') as archivo:\n",
    "    for ruta in rutas_archivos:\n",
    "        hilo = obtener_hilo_desde_ruta(ruta)\n",
    "        nombre_archivo = os.path.basename(ruta)\n",
    "        archivo.write(f\"{nombre_archivo}\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
