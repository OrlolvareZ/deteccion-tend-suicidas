{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fBq1jPuAhr0Y"
   },
   "source": [
    "# Preprocesamiento de hilos en 4chan\n",
    "\n",
    "En este cuaderno se procesan las publicaciones de 4chan, obtenidas a través de [web scrapping](./Scraper-4chan). Estas publicaciones pertenecen a múltiples [hilos que son considerados pertinentes]() para el objetivo de la investigación, ya sea por su idiosincrática nocividad en el uso del lenguaje, por la expresión misma de ideaciones/intenciones suicidas, o por contener sugerencias para llevar a cabo el suicidio.\n",
    "\n",
    "El objetivo de este cuaderno es retirar caracteres inútiles, transformar el contenido de cada publicación a minúsculas y eliminar los saltos de lí­nea en cada publicación. Además, es posible emplear una lista de palabras objetivo y localizar las publicaciones que contengan alguna de ellas.\n",
    "\n",
    "Para esta tarea se utilizará la librería de `pandas`, pues su parser de archivos `.csv` admite por defecto el uso de saltos de lí­nea en los campos de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TwNbWjYBdYmG"
   },
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import pandas\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NPgNh-OHgOlo"
   },
   "source": [
    "A raíz de que se han consultado (y se consultarán) múltiples hilos, este script lee todas las publicaciones de los hilos y realiza múltiples operaciones sobre ellos.\n",
    "\n",
    "A su vez, se crea una lista de nombres de archivos ya procesados, para excluirlos de la lectura cuando se trabaje en sesiones posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yCRhJJVujCpw"
   },
   "outputs": [],
   "source": [
    "# Función para encontrar archivos\n",
    "\n",
    "def encontrar_archivos(patron: str, ruta_base: str, lista_ex: list, verbose: bool = False):\n",
    "\n",
    "    archivos = []\n",
    "    index = 1\n",
    "\n",
    "    for root, _, files in os.walk(ruta_base):\n",
    "\n",
    "        for name in files:\n",
    "\n",
    "            if fnmatch.fnmatch(name, patron) and name not in lista_ex:\n",
    "                archivos.append(os.path.join(root, name))\n",
    "                if verbose:\n",
    "                    print(f'Archivo #{index}: {name}')\n",
    "                    index += 1\n",
    "\n",
    "    return archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3-RCHV0dpx25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahorcarme_complete.csv', 'colgarme_complete.csv', '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos los archivos ya procesados desde un archivo de texto\n",
    "archivos_procesados = []\n",
    "\n",
    "with open('./datos/lista_procesados.txt', 'r') as archivo: \n",
    "    for linea in archivo:\n",
    "        archivos_procesados.append(linea.strip())\n",
    "\n",
    "archivos_de_la_sesion = []\n",
    "archivos_procesados[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4P4rzornxiM",
    "outputId": "d1cb428b-11ff-4dc2-d1ff-b80332e2c8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo #1: 1436774 - comments & replies.csv\n",
      "Archivo #2: 17913796 - comments & replies.csv\n",
      "Archivo #3: 17918614 - comments & replies.csv\n",
      "Archivo #4: 17927427 - comments & replies.csv\n",
      "Archivo #5: 17927993 - comments & replies.csv\n",
      "Archivo #6: 17928132 - comments & replies.csv\n",
      "Archivo #7: 17929614 - comments & replies.csv\n",
      "Archivo #8: 17929761 - comments & replies.csv\n",
      "Archivo #9: 17930158 - comments & replies.csv\n",
      "Archivo #10: 17930355 - comments & replies.csv\n",
      "Archivo #11: 1973636 - comments & replies.csv\n",
      "Archivo #12: 2458998 - comments & replies.csv\n",
      "Archivo #13: 2478234 - comments & replies.csv\n",
      "Archivo #14: 2481228 - comments & replies.csv\n",
      "Archivo #15: 2481880 - comments & replies.csv\n",
      "Archivo #16: 2483351 - comments & replies.csv\n",
      "Archivo #17: 2484336 - comments & replies.csv\n",
      "Archivo #18: 2486136 - comments & replies.csv\n",
      "Archivo #19: 2486883 - comments & replies.csv\n",
      "Archivo #20: 2487974 - comments & replies.csv\n",
      "Archivo #21: 2669577 - comments & replies.csv\n",
      "Archivo #22: 2694142 - comments & replies.csv\n",
      "Archivo #23: 2784621 - comments & replies.csv\n",
      "Archivo #24: 2786465 - comments & replies.csv\n",
      "Archivo #25: 901315457 - comments & replies.csv\n",
      "Archivo #26: 901318661 - comments & replies.csv\n",
      "Archivo #27: 901329914 - comments & replies.csv\n",
      "Archivo #28: 901330002 - comments & replies.csv\n",
      "Archivo #29: 901330271 - comments & replies.csv\n"
     ]
    }
   ],
   "source": [
    "rutas_archivos = []\n",
    "rutas_base = [\n",
    "    './datos/hilos_4chan',\n",
    "]\n",
    "\n",
    "for ruta in rutas_base:\n",
    "    rutas_archivos.extend(\n",
    "        encontrar_archivos(\n",
    "            patron='*.csv',\n",
    "            ruta_base=ruta,\n",
    "            lista_ex=archivos_procesados,\n",
    "            verbose=True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s1SG0Yquxmfj"
   },
   "source": [
    "Los archivos contienen saltos de línea dentro de los campos, y las respuestas a un comentario raíz tienen el prefijo \"(REPLY) >>\", seguido del número del usuario. Esto se eliminará de las publicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XkDtJOpN7E70"
   },
   "outputs": [],
   "source": [
    "def pre_procesar_dataset(dataset: pandas.DataFrame):\n",
    "\n",
    "    # Se eliminan los saltos de línea y los nombres de usuario en las publicaciones/respuestas\n",
    "    dataset['comment/reply'] = dataset['comment/reply'].str.replace('\\n', ' ')\n",
    "    dataset['comment/reply'] = dataset['comment/reply'].str.replace(\n",
    "        '((\\(REPLY\\))?\\s>>.{8})|>', '', regex=True)\n",
    "    dataset['comment/reply'] = dataset['comment/reply'].str.lstrip()\n",
    "    # Se retiran las columnas que no se usarán\n",
    "    columnas = [\n",
    "        'post_id',\n",
    "        'subject',\n",
    "        'name',\n",
    "        'is_op?',\n",
    "    ]\n",
    "    dataset.drop(columns=columnas, inplace=True)\n",
    "    # Se renombran las columnas -> Esta adecuación se hace para darles un formato similar a los dataframes de Twitter,\n",
    "    # para que en algún momento sean más sencillos de procesar bajo el mismo conjunto de instrucciones\n",
    "    dataset.rename(\n",
    "        columns={\n",
    "            'date_time': 'Date',\n",
    "            'comment/reply': 'Content',\n",
    "            'url': 'URL'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # Se eliminan las filas que no tienen contenido\n",
    "    dataset.dropna(subset=['Content'], inplace=True)\n",
    "\n",
    "def obtener_hilo_desde_ruta(ruta: str):\n",
    "    # Para conocer el hilo, se obtiene el nombre del directorio padre de la ruta\n",
    "    nombre_hilo = os.path.basename(os.path.dirname(ruta))\n",
    "    # Se eliminan los números y el guión del nombre del hilo\n",
    "    nombre_hilo = re.sub(r'[0-9]*\\s-\\s', '', nombre_hilo)\n",
    "\n",
    "    return nombre_hilo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5E3QWpETr6um",
    "outputId": "371aad1a-a075-4931-8da7-28063abcf955"
   },
   "outputs": [],
   "source": [
    "# Se leen los archivos .csv encontrados\n",
    "datasets = []\n",
    "\n",
    "for ruta in rutas_archivos:\n",
    "\n",
    "    dataset = pandas.read_csv(ruta)\n",
    "    pre_procesar_dataset(dataset)\n",
    "\n",
    "    datasets.append(\n",
    "        {\n",
    "            \"hilo\": obtener_hilo_desde_ruta(ruta),\n",
    "            \"datos\": dataset,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZVwQ2mgxeeF5",
    "outputId": "2d03d619-dbef-431b-c860-2c8436516a58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jun-23-2023, 09:17:41</td>\n",
       "      <td>My balls is now hurts so much. Cirno is truly ...</td>\n",
       "      <td>http://boards.4chan.org/bant/thread/17927993/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jun-23-2023, 09:18:26</td>\n",
       "      <td>The humor stems from the fact that it is porno...</td>\n",
       "      <td>http://boards.4chan.org/bant/thread/17927993/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jun-23-2023, 09:18:45</td>\n",
       "      <td>i almost thought for a moment that the spic po...</td>\n",
       "      <td>http://boards.4chan.org/bant/thread/17927993/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jun-23-2023, 09:57:52</td>\n",
       "      <td>wtf Mono</td>\n",
       "      <td>http://boards.4chan.org/bant/thread/17927993/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jun-23-2023, 12:35:21</td>\n",
       "      <td>you need to go fucking kill yourself tiny whit...</td>\n",
       "      <td>http://boards.4chan.org/bant/thread/17927993/m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date                                            Content  \\\n",
       "0  Jun-23-2023, 09:17:41  My balls is now hurts so much. Cirno is truly ...   \n",
       "1  Jun-23-2023, 09:18:26  The humor stems from the fact that it is porno...   \n",
       "2  Jun-23-2023, 09:18:45  i almost thought for a moment that the spic po...   \n",
       "3  Jun-23-2023, 09:57:52                                           wtf Mono   \n",
       "4  Jun-23-2023, 12:35:21  you need to go fucking kill yourself tiny whit...   \n",
       "\n",
       "                                                 URL  \n",
       "0  http://boards.4chan.org/bant/thread/17927993/m...  \n",
       "1  http://boards.4chan.org/bant/thread/17927993/m...  \n",
       "2  http://boards.4chan.org/bant/thread/17927993/m...  \n",
       "3  http://boards.4chan.org/bant/thread/17927993/m...  \n",
       "4  http://boards.4chan.org/bant/thread/17927993/m...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observemos un ejemplo\n",
    "datasets[4]['datos'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos una columna con el nombre del hilo\n",
    "for dataset in datasets:\n",
    "    dataset['datos']['Thread'] = dataset['hilo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "un1Gfb1wX0_M"
   },
   "source": [
    "Una vez preparados los datos, podemos guardar una copia de ellos para su futuro análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uTOhcKLz6wJ8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta creada: ./datos_limpios/4chan\n"
     ]
    }
   ],
   "source": [
    "# Creamos la ruta donde se guardarán los archivos\n",
    "ruta_guardado = \"./datos_limpios/4chan\"\n",
    "sufijo = \"_cleaned.csv\"\n",
    "\n",
    "os.makedirs(ruta_guardado, exist_ok=True)\n",
    "print(f'Ruta creada: {ruta_guardado}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_ in datasets:\n",
    "    hilo = dict_['hilo']\n",
    "    dataset = dict_['datos']\n",
    "    nombre_guardado_full = f\"{ruta_guardado}/{hilo}{sufijo}\"\n",
    "    dataset.to_csv(nombre_guardado_full, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que agregamos información del hilo al que pertenece, podemos juntar todas las publicaciones en un solo archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = pandas.concat([dict_['datos'] for dict_ in datasets])\n",
    "# Guardamos el dataset sin números de fila\n",
    "dataset_full.to_csv(f\"{ruta_guardado}/dataset_4chan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlF01iyjZtO9"
   },
   "source": [
    "Además, podemos leer una serie de palabras relevantes de un archivo, para después obtener únicamente publicaciones que las contienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rrySYzLKZkqc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algunas de las palabras son:  ['suicide', 'suicidal', 'suic', 'self-harm', 'self-injury']\n"
     ]
    }
   ],
   "source": [
    "ruta_archivo_palabras = './datos_p_filtrar/palabras_objetivo.txt'\n",
    "\n",
    "with open(ruta_archivo_palabras, 'r') as archivo:\n",
    "    palabras = archivo.readlines()\n",
    "    palabras = [palabra.replace('\\n', '') for palabra in palabras]\n",
    "    print(\"Algunas de las palabras son: \", palabras[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos el dataset completo y recuperamos las publicaciones que contengan las palabras objetivo\n",
    "dataset_full = pandas.read_csv(f\"{ruta_guardado}/dataset_4chan.csv\")\n",
    "\n",
    "# Quitamos las filas que no tienen contenido\n",
    "dataset_full.dropna(subset=['Content'], inplace=True)\n",
    "\n",
    "# Preprocesamos la lista de palabras objetivo para que sean útiles como expresiones regulares\n",
    "palabras = [palabra.replace(' ', '\\\\s') for palabra in palabras]\n",
    "\n",
    "# Mantenemos las filas que contengan las palabras objetivo\n",
    "dataset_full = dataset_full[\n",
    "    dataset_full['Content'].str.contains(\n",
    "        '|'.join(palabras),\n",
    "        regex=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full.to_csv(f\"{ruta_guardado}/dataset_4chan_keywords_only.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para posteriores análisis, podemos decidir guardar los archivos procesados en la lista, para indicar que terminamos de correrlos por el pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anexamos los archivos procesados en esta sesión a la lista de archivos procesados\n",
    "\n",
    "with open('./datos/lista_procesados.txt', 'a') as archivo:\n",
    "    for ruta in rutas_archivos:\n",
    "        hilo = obtener_hilo_desde_ruta(ruta)\n",
    "        nombre_archivo = os.path.basename(ruta)\n",
    "        archivo.write(f\"{nombre_archivo}\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
