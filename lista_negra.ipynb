{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuaderno de creación de lista negra de usuarios\n",
    "\n",
    "El código definido a continuación tiene como objetivo analizar las publicaciones de la carpeta [`datos`](/datos/), y crear una lista de usuarios que no deberían ser considerados en el análisis de datos.\n",
    "\n",
    "Se consideraran para esta lista usuarios que sean autores de: \n",
    "\n",
    "* Publicaciones hechas para fomentar el cuidado de la salud mental\n",
    "    * Si bien se pueden encontrar palabras clave que indiquen tendencias suicidas, no necesariamente reflejan problemas mentales en quien las publica\n",
    "* Publicaciones repetidas (spam o bots)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar las siguientes instrucciones, se empleará el lenguaje de R.\n",
    "\n",
    "Será de utilidad en el análisis, además, el paquete `tm`, que permite realizar análisis sobre texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Instalar paquetes necesarios\n",
    "install.packages(\n",
    "    c(\n",
    "        \"tm\",\n",
    "        \"dplyr\",\n",
    "        \"stringr\",\n",
    "        \"SnowballC\"\n",
    "    ),\n",
    "    repos = \"http://cran.us.r-project.org\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tm' was built under R version 4.2.3\"\n",
      "Loading required package: NLP\n",
      "\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'stringr' was built under R version 4.2.3\"\n",
      "Warning message:\n",
      "\"package 'SnowballC' was built under R version 4.2.3\"\n"
     ]
    }
   ],
   "source": [
    "# Se cargan las librerías\n",
    "library('tm')\n",
    "library('dplyr')\n",
    "library('stringr')\n",
    "library('SnowballC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Se carga el archivo de texto\n",
    "publicaciones_ahorcarme <- read.csv(\"./datos/ahorcarme_complete.csv\")\n",
    "publicaciones_colgarme <- read.csv(\"./datos/colgarme_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(publicaciones_ahorcarme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Obtenemos del dataframe las que tengan usuarios que aparezcan más de N veces\n",
    "\n",
    "obtener_publicaciones <- function(dataframe, pub_minimas) {\n",
    "\n",
    "    dataframe <- dataframe %>% \n",
    "        group_by(User) %>% \n",
    "        filter(n() > pub_minimas)\n",
    "\n",
    "    return(dataframe)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filtramos los usuarios que tengan más de 5 publicaciones\n",
    "publicaciones_ahorcarme_reducidas <- obtener_publicaciones(publicaciones_ahorcarme, 5)\n",
    "publicaciones_colgarme_reducidas <- obtener_publicaciones(publicaciones_colgarme, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Se juntan los vectores que contienen los nombres de los usuarios, para ser unificados en una sola lista negra\n",
    "# Se le suministrarán varios vectores de usuarios, y se devolverá un vector con los usuarios únicos\n",
    "\n",
    "juntar_usuarios <- function(listas_usuarios) {\n",
    "\n",
    "    usuarios <- c()\n",
    "\n",
    "    for (lista in listas_usuarios) {\n",
    "        usuarios <- c(usuarios, lista)\n",
    "    }\n",
    "\n",
    "    usuarios <- unique(usuarios)\n",
    "\n",
    "    return(usuarios)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos la lista de los usuarios que aparecen más de 5 veces en las publicaciones\n",
    "\n",
    "usuarios_ahorcarme <- publicaciones_ahorcarme_reducidas$User\n",
    "usuarios_colgarme <- publicaciones_colgarme_reducidas$User\n",
    "\n",
    "lista_negra <- juntar_usuarios(\n",
    "    c(\n",
    "        usuarios_ahorcarme,\n",
    "        usuarios_colgarme\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(lista_negra)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos revisar manualmente los tweets de los usuarios que colocamos en la lista negra bajo este criterio, para determinar si realmente sus publicaciones son despreciables para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Obtenemos los tweets de estos usuarios, para revisarlos manualmente\n",
    "\n",
    "# Ahorcarme\n",
    "tweets_lisneg_ahorcarme <- publicaciones_ahorcarme_reducidas %>%\n",
    "    filter(User %in% lista_negra)\n",
    "\n",
    "# Colgarme\n",
    "tweets_lisneg_colgarme <- publicaciones_colgarme_reducidas %>%\n",
    "    filter(User %in% lista_negra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos los tweets en un archivo\n",
    "\n",
    "# Ahorcarme\n",
    "write.table(\n",
    "    tweets_lisneg_ahorcarme,\n",
    "    file = \"./datos_limpios/tweets_lisneg_ahorcarme.csv\",\n",
    "    row.names = FALSE,\n",
    "    col.names = TRUE,\n",
    "    quote = TRUE,\n",
    "    sep = \",\"\n",
    ")\n",
    "\n",
    "# Colgarme\n",
    "write.table(\n",
    "    tweets_lisneg_colgarme,\n",
    "    file = \"./datos_limpios/tweets_lisneg_colgarme.csv\",\n",
    "    row.names = FALSE,\n",
    "    col.names = TRUE,\n",
    "    quote = TRUE,\n",
    "    sep = \",\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de revisar los tweets, encontré un fragmento que hace alusión a una connotación sexual de la palabra concurrente. Por lo tanto, aquellos usuarios cuyas publicaciones que contienen la palabra \"ahorcarme\" serán añadidos a la lista negra.\n",
    "\n",
    "Es importante considerar que, si bien emplean la palabra bajo un concepto sexual, puede no ser la única forma en la que la usan; de hecho, logré encontrar varios perfiles en los que hacen un uso sexual y violento del verbo. De tal manera, de este grupo de usuarios que tergiversan de esta forma la acción, únicamente se seleccionarán aquellos que emplean la palabra exclusivamente en un contexto sexual, es decir, en todos los tweets que les fueron recolectados que les pertenecen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Función que obtiene los tweets de un usuario y determina si todos contienen un texto clave\n",
    "\n",
    "tweetsSonRepetitivos <- function(dataset, usuario, textoClave) {\n",
    "    # Obtenemos los tweets del usuario\n",
    "    tweets <- dataset %>%\n",
    "        filter(User %in% usuario) %>%\n",
    "        select(Content)\n",
    "    \n",
    "    # Revisamos si todos los tweets contienen el texto clave\n",
    "    tweets_contienen_texto <- sum(grepl(textoClave, as.vector(tweets$Content), ignore.case = TRUE))\n",
    "    todosContienen <- tweets_contienen_texto == nrow(tweets)\n",
    "    \n",
    "    return (todosContienen)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Función que toma un dataset y una serie de textos clave, y devuelve los usuarios que tienen todos\n",
    "# sus tweets con al menos uno de esos textos clave\n",
    "\n",
    "obtenerUsuariosRepetitivos <- function(dataset, textosClave) {\n",
    "    # Obtenemos los usuarios\n",
    "    usuarios <- dataset %>%\n",
    "        select(User) %>%\n",
    "        unique()\n",
    "    \n",
    "    # Obtenemos los usuarios que tienen todos sus tweets con el texto clave\n",
    "    usuarios_repetitivos <- c()\n",
    "    \n",
    "    for (usuario in usuarios$User) {\n",
    "\n",
    "        for (textoClave in textosClave) {\n",
    "\n",
    "            if (tweetsSonRepetitivos(dataset, usuario, textoClave)) {\n",
    "                usuarios_repetitivos <- c(usuarios_repetitivos, usuario)\n",
    "                break\n",
    "            }\n",
    "\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return (unique(usuarios_repetitivos))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fragmento\n",
    "frags_frase = c(\n",
    "    \"ahorcame por dios ahorcame hasta el punto de que tus manos\"\n",
    ")\n",
    "\n",
    "# Localizar los tweets que contengan la frase, y de ellos tomar los usuarios, para agregarlos a los que ya\n",
    "# estaban listados, siempre y cuando todos los tweets del usuario contengan la frase\n",
    "\n",
    "usuarios_frags_ahorcarme <- obtenerUsuariosRepetitivos(publicaciones_ahorcarme, frags_frase)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro son fragmentos de una canción, en los tweets con la palabra clave \"colgarme\" (que se refieren a una acción como \"depender de\" o \"aprovecharse de\").\n",
    "\n",
    "Los fragmentos son los siguientes:\n",
    "\n",
    "<blockquote>\n",
    "    <ul>\n",
    "        <li> Niña, dame una pestaña de tus ojos para colgarme de amor por ti </li>\n",
    "        <li> Colgarme de cualquiera que le gusta trasnochar </li>\n",
    "    </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fragmentos\n",
    "frags_frase = c(\n",
    "    \"Niña, dame una pestaña de tus ojos para colgarme de amor por ti\",\n",
    "    \"Colgarme de cualquiera que le gusta trasnochar\",\n",
    ")\n",
    "# Localizar los tweets que contengan la frase, y de ellos tomar los usuarios, para agregarlos a los que ya\n",
    "# estaban listados.\n",
    "\n",
    "usuarios_frag_colgarme <- obtenerUsuariosRepetitivos(publicaciones_colgarme, frags_frase)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igualmente, se removerá cualquier uso de la llamada en el contexto de una conversación telefónica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "raiz_verbo_aparece <- function(texto, raices_a_comparar, lenguage) {\n",
    "\n",
    "    palabras <- unlist(strsplit(texto, \" \"))\n",
    "    raices_palabras <- wordStem(palabras, language = lenguage)\n",
    "    \n",
    "    for (raiz_palabra in raices_palabras) {\n",
    "        \n",
    "        for (raiz_verbo in raices_a_comparar) {\n",
    "            \n",
    "            if ( grepl(raiz_verbo, raiz_palabra) ) {\n",
    "                return(TRUE)\n",
    "            }\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    return(FALSE)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Usando el paquete tm, se buscarán los tweets que contengan alguna conjugación de la palabras\n",
    "# \"llamar\", \"marcar\", \"responder\", \"contestar\"\n",
    "\n",
    "# Obtenemos primero las raíces de esos verbos, para saber cuáles raíces buscar\n",
    "palabras_contexto_telefonico <- c(\n",
    "    \"llamar\",\n",
    "    \"marcar\",\n",
    "    \"responder\",\n",
    "    \"contestar\"\n",
    ")\n",
    "\n",
    "raices_palabras_contexto_telefonico <- wordStem(palabras_contexto_telefonico, language = \"spanish\")\n",
    "print(raices_palabras_contexto_telefonico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Para cada tweet, se buscará si contiene alguna de las raíces de las palabras, y si es así, se agregará el índice del tweet\n",
    "# a una lista, para ser removido posteriormente.\n",
    "# No quitamos al usuario completamente porque el uso de la palabra \"colgar\" en una llamada no le excluye de usarla con\n",
    "# intenciones autolesivas\n",
    "\n",
    "tweets_colgarme_limpios <- publicaciones_colgarme %>%\n",
    "    mutate(\n",
    "        contexto_telefonico = sapply(Content, raiz_verbo_aparece, raices_palabras_contexto_telefonico, \"spanish\")\n",
    "    ) %>%\n",
    "    # Filtramos los tweets que no usen el verbo para referirse a una llamada\n",
    "    filter(contexto_telefonico == FALSE) %>%\n",
    "    # Excluimos la columna que ya no nos sirve\n",
    "    select(-contexto_telefonico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Agregar los usuarios a la lista de usuarios\n",
    "\n",
    "lista_negra <- juntar_usuarios(\n",
    "    c(\n",
    "        lista_negra,\n",
    "        usuarios_frags_ahorcarme,\n",
    "        usuarios_frag_colgarme\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "writeLines(usuarios_frag_colgarme, \"usuarios_frag_colgarme.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Escribir la lista negra en un archivo\n",
    "writeLines(\n",
    "    lista_negra,\n",
    "    file = \"./datos_limpios/lista_negra.txt\",\n",
    "    row.names = FALSE,\n",
    "    col.names = FALSE,\n",
    "    quote = FALSE,\n",
    "    sep = \",\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aquí, una vez que hallamos revisado la lista negra de usuarios, vamos a limpiar los conjuntos de datos para obtener únicamente la información útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Excluir a estos usuarios de los datasets, pero a partir de la lista negra de usuarios ya revisada\n",
    "\n",
    "# Leer lista\n",
    "lista_negra_revisada <- readLines(\"./datos_limpios/lista_negra_revisada.txt\", encoding = \"UTF-8\")\n",
    "\n",
    "# Ahorcarme\n",
    "publicaciones_ahorcarme <- publicaciones_ahorcarme %>%\n",
    "    filter(!User %in% lista_negra_revisada)\n",
    "\n",
    "# Colgarme\n",
    "publicaciones_colgarme <- tweets_colgarme_limpios %>%\n",
    "    filter(!User %in% lista_negra_revisada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos los tweets en un archivo\n",
    "\n",
    "# Ahorcarme\n",
    "write.table(\n",
    "    publicaciones_ahorcarme,\n",
    "    file = \"./datos_limpios/ahorcarme_filtered.csv\",\n",
    "    row.names = FALSE,\n",
    "    col.names = TRUE,\n",
    "    quote = TRUE,\n",
    "    sep = \",\"\n",
    ")\n",
    "\n",
    "# Colgarme\n",
    "write.table(\n",
    "    publicaciones_colgarme,\n",
    "    file = \"./datos_limpios/colgarme_filtered.csv\",\n",
    "    row.names = FALSE,\n",
    "    col.names = TRUE,\n",
    "    quote = TRUE,\n",
    "    sep = \",\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
