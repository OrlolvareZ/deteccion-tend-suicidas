{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuaderno de creación de lista negra de usuarios\n",
    "\n",
    "El código definido a continuación tiene como objetivo analizar las publicaciones de la carpeta [`datos`](/datos/), y crear una lista de usuarios que no deberían ser considerados en el análisis de datos.\n",
    "\n",
    "Se consideraran para esta lista usuarios que sean autores de: \n",
    "\n",
    "* Publicaciones hechas para fomentar el cuidado de la salud mental\n",
    "    * Si bien se pueden encontrar palabras clave que indiquen tendencias suicidas, no necesariamente reflejan problemas mentales en quien las publica\n",
    "* Publicaciones repetidas (spam o bots)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar las siguientes instrucciones, se empleará el lenguaje de R.\n",
    "\n",
    "Será de utilidad en el análisis, además, el paquete `tm`, que permite realizar análisis sobre texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing packages into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Warning message in install.packages(c(\"tm\", \"dplyr\", \"stringr\", \"SnowballC\"), repos = \"http://cran.us.r-project.org\"):\n",
      "“'lib = \"/usr/local/lib/R/site-library\"' is not writable”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in install.packages(c(\"tm\", \"dplyr\", \"stringr\", \"SnowballC\"), repos = \"http://cran.us.r-project.org\"): unable to install packages\n",
     "output_type": "error",
     "traceback": [
      "Error in install.packages(c(\"tm\", \"dplyr\", \"stringr\", \"SnowballC\"), repos = \"http://cran.us.r-project.org\"): unable to install packages\nTraceback:\n",
      "1. install.packages(c(\"tm\", \"dplyr\", \"stringr\", \"SnowballC\"), repos = \"http://cran.us.r-project.org\")",
      "2. stop(\"unable to install packages\")"
     ]
    }
   ],
   "source": [
    "# Instalar paquetes necesarios\n",
    "install.packages(\n",
    "    c(\n",
    "        \"tm\",\n",
    "        \"dplyr\",\n",
    "        \"stringr\",\n",
    "        \"SnowballC\"\n",
    "    ),\n",
    "    repos = \"http://cran.us.r-project.org\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tm' was built under R version 4.2.3\"\n",
      "Loading required package: NLP\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 4.2.3\"\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'SnowballC' was built under R version 4.2.3\"\n"
     ]
    }
   ],
   "source": [
    "# Se cargan las librerías\n",
    "library('tm')\n",
    "library('dplyr')\n",
    "library('SnowballC')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para optimizar el proceso de lectura de archivos, vamos a definir funciones que:\n",
    "\n",
    "* Descubran los archivos .csv dada una serie de carpetas base.\n",
    "* Extraigan el nombre de los mismos para renombrarlos de ser necesario.\n",
    "* Lean los archivos .csv y los conviertan en un dataframe de R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Definimos una lista de archivos ya procesados, de manera que no se carguen todos en cada sesión\n",
    "archivos_procesados <- readLines('./datos/lista_procesados.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Definimos una función que nos permita conocer las rutas de los archivos a procesar, dada una lista de carpetas base\n",
    "obtener_rutas <- function(carpetas) {\n",
    "\n",
    "    rutas <- c()\n",
    "\n",
    "    for (carpeta in carpetas) {\n",
    "\n",
    "        rutas <- c(\n",
    "            rutas, # Rutas anteriores\n",
    "            list.files(carpeta, pattern = \"*.csv\", full.names = TRUE) # Rutas de los archivos descubiertos\n",
    "        )\n",
    "    }\n",
    "\n",
    "    return(rutas)\n",
    "}\n",
    "\n",
    "# Definimos una función que nos de el nombre del archivo a partir de su ruta\n",
    "obtener_nombre_archivo <- function(ruta) {\n",
    "\n",
    "    # Separamos la ruta por las diagonales\n",
    "    ruta_separada <- strsplit(ruta, \"/\", fixed = TRUE)[[1]]\n",
    "\n",
    "    # Obtenemos el último elemento de la ruta\n",
    "    nombre_archivo <- ruta_separada[length(ruta_separada)]\n",
    "\n",
    "    return(nombre_archivo)\n",
    "}\n",
    "\n",
    "# Función que lee los archivos y devuelve una lista de tuplas con el nombre del archivo y el contenido,\n",
    "# siempre y cuando el archivo no haya sido procesado previamente\n",
    "leer_archivos <- function(rutas, archivos_procesados) {\n",
    "\n",
    "    # Lista de tuplas\n",
    "    archivos <- list()\n",
    "\n",
    "    for (ruta in rutas) {\n",
    "\n",
    "        nombre_archivo <- obtener_nombre_archivo(ruta)\n",
    "\n",
    "        if (!(nombre_archivo %in% archivos_procesados)) {\n",
    "\n",
    "            datos_ <- read.csv(file = ruta)\n",
    "            \n",
    "            # Agregamos el nombre del archivo y su contenido a la lista\n",
    "            archivos <- append(\n",
    "                archivos,\n",
    "                list( # El método append toma las dos listas y las junta en una sola\n",
    "                    list( # Por eso, la lista contiene otra lista, que es una tupla\n",
    "                        nombre = nombre_archivo,\n",
    "                        datos = datos_\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        }\n",
    "    }\n",
    "\n",
    "    return(archivos)\n",
    "}\n",
    "\n",
    "# Finalmente, establecemos una función que descubra los archivos a procesar, los lea y los devuelva\n",
    "obtener_datos <- function(carpetas, archivos_procesados, verbose) {\n",
    "\n",
    "    # Obtenemos las rutas de los archivos a procesar\n",
    "    rutas <- obtener_rutas(carpetas)\n",
    "\n",
    "    # Leemos los archivos\n",
    "    archivos <- leer_archivos(rutas, archivos_procesados)\n",
    "\n",
    "    if (verbose) { # Si se solicita, imprimimos los archivos encontrados\n",
    "\n",
    "        print('Se encontraron los siguientes archivos:')\n",
    "\n",
    "        for (archivo in archivos) {\n",
    "\n",
    "            print(archivo$nombre)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return(archivos)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Se encontraron los siguientes archivos:\"\n",
      "[1] \"necesito_ayuda_complete.csv\"\n",
      "[1] \"perdon_por_todo_complete.csv\"\n",
      "[1] \"queria_estar_muerto_complete.csv\"\n",
      "[1] \"queria_morir_complete.csv\"\n",
      "[1] \"quiero_estar_muerto_complete.csv\"\n",
      "[1] \"quisiera_estar_muerto_complete.csv\"\n",
      "[1] \"suicida_complete.csv\"\n"
     ]
    }
   ],
   "source": [
    "# Leeremos los archivos .csv de las carpetas especificadas\n",
    "carpetas_a_explorar <- c(\n",
    "    './datos/twitter/'\n",
    ")\n",
    "\n",
    "datos <- obtener_datos(carpetas_a_explorar, archivos_procesados, verbose = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"necesito_ayuda_complete.csv\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>User</th><th scope=col>Content</th><th scope=col>Date</th><th scope=col>URL</th><th scope=col>Coordinates</th><th scope=col>Place</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>alezam2009     </td><td>Estoy jugando #VenezuelaQuiz y necesito ayuda con esta imagen ¿La reconoces? http://t.co/usqusrfmbN                                        </td><td>2014-12-30 23:59:47</td><td>https://twitter.com/alezam2009/status/550078827410362368     </td><td>NA                                                   </td><td>NA                                                                                                                             </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>ValentinaMotto1</td><td>No paro de llorar , necesito ayuda !!                                                                                                      </td><td>2014-12-30 23:58:41</td><td>https://twitter.com/ValentinaMotto1/status/550078552461561859</td><td>Coordinates(longitude=-64.3195, latitude=-31.5235762)</td><td>Place(id='00f84d414936f28e', fullName='Córdoba, Argentina', name='Córdoba', type='city', country='Argentina', countryCode='AR')</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>dulcelado      </td><td>@LOURDEATH Me re vicié, necesito ayuda                                                                                                     </td><td>2014-12-30 23:57:12</td><td>https://twitter.com/dulcelado/status/550078180162560002      </td><td>NA                                                   </td><td>NA                                                                                                                             </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>BeatrizRifo    </td><td>@leonardofarkas por favor don Leonardo farkas necesito su ayuda para arreglar mis dientes no tengo a quien mas recurrir mil gracias gracias</td><td>2014-12-30 23:55:51</td><td>https://twitter.com/BeatrizRifo/status/550077838112870400    </td><td>NA                                                   </td><td>NA                                                                                                                             </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>bbhdalnim      </td><td>necesito ayuda                                                                                                                             </td><td>2014-12-30 23:54:39</td><td>https://twitter.com/bbhdalnim/status/550077536042905601      </td><td>NA                                                   </td><td>NA                                                                                                                             </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>lostandbroken13</td><td>Necesito vuestra ayuda.                                                                                                                    </td><td>2014-12-30 23:53:03</td><td>https://twitter.com/lostandbroken13/status/550077135562747904</td><td>NA                                                   </td><td>NA                                                                                                                             </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & User & Content & Date & URL & Coordinates & Place\\\\\n",
       "  & <chr> & <chr> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & alezam2009      & Estoy jugando \\#VenezuelaQuiz y necesito ayuda con esta imagen ¿La reconoces? http://t.co/usqusrfmbN                                         & 2014-12-30 23:59:47 & https://twitter.com/alezam2009/status/550078827410362368      & NA                                                    & NA                                                                                                                             \\\\\n",
       "\t2 & ValentinaMotto1 & No paro de llorar , necesito ayuda !!                                                                                                       & 2014-12-30 23:58:41 & https://twitter.com/ValentinaMotto1/status/550078552461561859 & Coordinates(longitude=-64.3195, latitude=-31.5235762) & Place(id='00f84d414936f28e', fullName='Córdoba, Argentina', name='Córdoba', type='city', country='Argentina', countryCode='AR')\\\\\n",
       "\t3 & dulcelado       & @LOURDEATH Me re vicié, necesito ayuda                                                                                                      & 2014-12-30 23:57:12 & https://twitter.com/dulcelado/status/550078180162560002       & NA                                                    & NA                                                                                                                             \\\\\n",
       "\t4 & BeatrizRifo     & @leonardofarkas por favor don Leonardo farkas necesito su ayuda para arreglar mis dientes no tengo a quien mas recurrir mil gracias gracias & 2014-12-30 23:55:51 & https://twitter.com/BeatrizRifo/status/550077838112870400     & NA                                                    & NA                                                                                                                             \\\\\n",
       "\t5 & bbhdalnim       & necesito ayuda                                                                                                                              & 2014-12-30 23:54:39 & https://twitter.com/bbhdalnim/status/550077536042905601       & NA                                                    & NA                                                                                                                             \\\\\n",
       "\t6 & lostandbroken13 & Necesito vuestra ayuda.                                                                                                                     & 2014-12-30 23:53:03 & https://twitter.com/lostandbroken13/status/550077135562747904 & NA                                                    & NA                                                                                                                             \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 6\n",
       "\n",
       "| <!--/--> | User &lt;chr&gt; | Content &lt;chr&gt; | Date &lt;chr&gt; | URL &lt;chr&gt; | Coordinates &lt;chr&gt; | Place &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1 | alezam2009      | Estoy jugando #VenezuelaQuiz y necesito ayuda con esta imagen ¿La reconoces? http://t.co/usqusrfmbN                                         | 2014-12-30 23:59:47 | https://twitter.com/alezam2009/status/550078827410362368      | NA                                                    | NA                                                                                                                              |\n",
       "| 2 | ValentinaMotto1 | No paro de llorar , necesito ayuda !!                                                                                                       | 2014-12-30 23:58:41 | https://twitter.com/ValentinaMotto1/status/550078552461561859 | Coordinates(longitude=-64.3195, latitude=-31.5235762) | Place(id='00f84d414936f28e', fullName='Córdoba, Argentina', name='Córdoba', type='city', country='Argentina', countryCode='AR') |\n",
       "| 3 | dulcelado       | @LOURDEATH Me re vicié, necesito ayuda                                                                                                      | 2014-12-30 23:57:12 | https://twitter.com/dulcelado/status/550078180162560002       | NA                                                    | NA                                                                                                                              |\n",
       "| 4 | BeatrizRifo     | @leonardofarkas por favor don Leonardo farkas necesito su ayuda para arreglar mis dientes no tengo a quien mas recurrir mil gracias gracias | 2014-12-30 23:55:51 | https://twitter.com/BeatrizRifo/status/550077838112870400     | NA                                                    | NA                                                                                                                              |\n",
       "| 5 | bbhdalnim       | necesito ayuda                                                                                                                              | 2014-12-30 23:54:39 | https://twitter.com/bbhdalnim/status/550077536042905601       | NA                                                    | NA                                                                                                                              |\n",
       "| 6 | lostandbroken13 | Necesito vuestra ayuda.                                                                                                                     | 2014-12-30 23:53:03 | https://twitter.com/lostandbroken13/status/550077135562747904 | NA                                                    | NA                                                                                                                              |\n",
       "\n"
      ],
      "text/plain": [
       "  User           \n",
       "1 alezam2009     \n",
       "2 ValentinaMotto1\n",
       "3 dulcelado      \n",
       "4 BeatrizRifo    \n",
       "5 bbhdalnim      \n",
       "6 lostandbroken13\n",
       "  Content                                                                                                                                    \n",
       "1 Estoy jugando #VenezuelaQuiz y necesito ayuda con esta imagen ¿La reconoces? http://t.co/usqusrfmbN                                        \n",
       "2 No paro de llorar , necesito ayuda !!                                                                                                      \n",
       "3 @LOURDEATH Me re vicié, necesito ayuda                                                                                                     \n",
       "4 @leonardofarkas por favor don Leonardo farkas necesito su ayuda para arreglar mis dientes no tengo a quien mas recurrir mil gracias gracias\n",
       "5 necesito ayuda                                                                                                                             \n",
       "6 Necesito vuestra ayuda.                                                                                                                    \n",
       "  Date               \n",
       "1 2014-12-30 23:59:47\n",
       "2 2014-12-30 23:58:41\n",
       "3 2014-12-30 23:57:12\n",
       "4 2014-12-30 23:55:51\n",
       "5 2014-12-30 23:54:39\n",
       "6 2014-12-30 23:53:03\n",
       "  URL                                                          \n",
       "1 https://twitter.com/alezam2009/status/550078827410362368     \n",
       "2 https://twitter.com/ValentinaMotto1/status/550078552461561859\n",
       "3 https://twitter.com/dulcelado/status/550078180162560002      \n",
       "4 https://twitter.com/BeatrizRifo/status/550077838112870400    \n",
       "5 https://twitter.com/bbhdalnim/status/550077536042905601      \n",
       "6 https://twitter.com/lostandbroken13/status/550077135562747904\n",
       "  Coordinates                                          \n",
       "1 NA                                                   \n",
       "2 Coordinates(longitude=-64.3195, latitude=-31.5235762)\n",
       "3 NA                                                   \n",
       "4 NA                                                   \n",
       "5 NA                                                   \n",
       "6 NA                                                   \n",
       "  Place                                                                                                                          \n",
       "1 NA                                                                                                                             \n",
       "2 Place(id='00f84d414936f28e', fullName='Córdoba, Argentina', name='Córdoba', type='city', country='Argentina', countryCode='AR')\n",
       "3 NA                                                                                                                             \n",
       "4 NA                                                                                                                             \n",
       "5 NA                                                                                                                             \n",
       "6 NA                                                                                                                             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(datos[[1]]$nombre)\n",
    "head(datos[[1]]$datos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, reduciremos el tamaño de los conjuntos de datos, y mantendremos sólo aquellos usuarios con N publicaciones o más.\n",
    "\n",
    "Esto nos permitirá "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos una función que nos permita localizar un dataframe en específico\n",
    "\n",
    "obtener_dataframe <- function(nombre, datos) {\n",
    "\n",
    "    for (archivo in datos) {\n",
    "\n",
    "        if (archivo$nombre == nombre) {\n",
    "\n",
    "            return(archivo$datos)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return(NULL)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Obtenemos los datos del archivo 'ahorcarme_complete.csv'\n",
    "publicaciones_ahorcarme <- obtener_dataframe('ahorcarme_complete.csv', datos)\n",
    "publicaciones_colgarme <- obtener_dataframe('colgarme_complete.csv', datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Obtenemos del dataframe las filas que tengan usuarios que aparezcan más de N veces\n",
    "\n",
    "obtener_publicaciones <- function(dataframe, pub_minimas) {\n",
    "\n",
    "    dataframe <- dataframe %>% \n",
    "        group_by(User) %>% \n",
    "        filter(n() > pub_minimas)\n",
    "\n",
    "    return(dataframe)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filtramos los usuarios que tengan más de 5 publicaciones\n",
    "publicaciones_ahorcarme_reducidas <- obtener_publicaciones(publicaciones_ahorcarme, 5)\n",
    "publicaciones_colgarme_reducidas <- obtener_publicaciones(publicaciones_colgarme, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Se juntan los vectores que contienen los nombres de los usuarios, para ser unificados en una sola lista negra\n",
    "# Se le suministrarán varios vectores de usuarios, y se devolverá un vector con los usuarios únicos\n",
    "\n",
    "juntar_usuarios <- function(listas_usuarios) {\n",
    "\n",
    "    usuarios <- c()\n",
    "\n",
    "    for (lista in listas_usuarios) {\n",
    "        usuarios <- c(usuarios, lista)\n",
    "    }\n",
    "\n",
    "    usuarios <- unique(usuarios)\n",
    "\n",
    "    return(usuarios)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos la lista de los usuarios que aparecen más de 5 veces en las publicaciones\n",
    "\n",
    "usuarios_ahorcarme <- publicaciones_ahorcarme_reducidas$User\n",
    "usuarios_colgarme <- publicaciones_colgarme_reducidas$User\n",
    "\n",
    "lista_negra <- juntar_usuarios(\n",
    "    c(\n",
    "        usuarios_ahorcarme,\n",
    "        usuarios_colgarme\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'soiiviic'</li><li>'gatoacostadou'</li><li>'Lucasnun_'</li><li>'cigarettommy'</li><li>'lwtironic'</li><li>'CyanideMoon'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'soiiviic'\n",
       "\\item 'gatoacostadou'\n",
       "\\item 'Lucasnun\\_'\n",
       "\\item 'cigarettommy'\n",
       "\\item 'lwtironic'\n",
       "\\item 'CyanideMoon'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'soiiviic'\n",
       "2. 'gatoacostadou'\n",
       "3. 'Lucasnun_'\n",
       "4. 'cigarettommy'\n",
       "5. 'lwtironic'\n",
       "6. 'CyanideMoon'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"soiiviic\"      \"gatoacostadou\" \"Lucasnun_\"     \"cigarettommy\" \n",
       "[5] \"lwtironic\"     \"CyanideMoon\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(lista_negra)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos revisar manualmente los tweets de los usuarios que colocamos en la lista negra bajo este criterio, para determinar si realmente sus publicaciones son despreciables para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Obtenemos los tweets de estos usuarios, para revisarlos manualmente\n",
    "\n",
    "# Ahorcarme\n",
    "tweets_lisneg_ahorcarme <- publicaciones_ahorcarme_reducidas %>%\n",
    "    filter(User %in% lista_negra)\n",
    "\n",
    "# Colgarme\n",
    "tweets_lisneg_colgarme <- publicaciones_colgarme_reducidas %>%\n",
    "    filter(User %in% lista_negra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "escribir_dataframe <- function(dataframe, ruta_archivo) {\n",
    "    write.table(\n",
    "        dataframe,\n",
    "        file = ruta_archivo,\n",
    "        row.names = FALSE,\n",
    "        col.names = TRUE,\n",
    "        quote = TRUE,\n",
    "        sep = \",\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos los tweets en un archivo\n",
    "\n",
    "# Ahorcarme\n",
    "escribir_dataframe(tweets_lisneg_ahorcarme, \"./datos_limpios/datos_por_revisar/tweets_lisneg_ahorcarme.csv\")\n",
    "# Colgarme\n",
    "escribir_dataframe(tweets_lisneg_colgarme, \"./datos_limpios/datos_por_revisar/tweets_lisneg_colgarme.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de revisar los tweets, encontré un fragmento que hace alusión a una connotación sexual de la palabra concurrente. Por lo tanto, aquellos usuarios cuyas publicaciones que contienen la palabra \"ahorcarme\" serán añadidos a la lista negra.\n",
    "\n",
    "Es importante considerar que, si bien emplean la palabra bajo un concepto sexual, puede no ser la única forma en la que la usan; de hecho, logré encontrar varios perfiles en los que hacen un uso sexual y violento del verbo. De tal manera, de este grupo de usuarios que tergiversan de esta forma la acción, únicamente se seleccionarán aquellos que emplean la palabra exclusivamente en un contexto sexual, es decir, en todos los tweets que les fueron recolectados que les pertenecen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Función que obtiene los tweets de un usuario y determina si todos contienen una serie de textos claves\n",
    "\n",
    "tweetsSonRepetitivos <- function(dataset, usuario, textosClave) {\n",
    "    # Obtenemos los tweets del usuario\n",
    "    tweets <- dataset %>%\n",
    "        filter(User == usuario) %>%\n",
    "        pull(Content) # pull() devuelve un vector con los valores de la columna\n",
    "    \n",
    "    # Revisamos si todos los tweets contienen alguno de los textos clave\n",
    "    for (texto in textosClave){\n",
    "        todosContienen <- all(grepl(texto, tweets, ignore.case = TRUE))\n",
    "\n",
    "        # Nos conformamos con saber que uno de los textos que deseamos excluir está en los tweets,\n",
    "        # pues es suficiente para determinar que el usuario repite contenido\n",
    "        if (todosContienen) {\n",
    "            return (TRUE)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return (todosContienen)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Función que toma un dataset y una serie de textos clave, y devuelve los usuarios que tienen todos\n",
    "# sus tweets con al menos uno de esos textos clave\n",
    "\n",
    "obtenerUsuariosRepetitivos <- function(dataset, textosClave) {\n",
    "    # Obtenemos los usuarios\n",
    "    usuarios <- dataset %>%\n",
    "        distinct(User) %>%\n",
    "        pull(User)\n",
    "        \n",
    "    # Obtenemos los usuarios que tienen todos sus tweets con alguno de sus textos clave en este vector\n",
    "    usuarios_repetitivos <- c()\n",
    "    \n",
    "    for (usuario in usuarios) {\n",
    "\n",
    "        if (tweetsSonRepetitivos(dataset, usuario, textosClave)) {\n",
    "            usuarios_repetitivos <- c(usuarios_repetitivos, usuario)\n",
    "            break\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return (unique(usuarios_repetitivos))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fragmento\n",
    "frags_frase = c(\n",
    "    \"ahorcame por dios ahorcame hasta el punto de que tus manos\"\n",
    ")\n",
    "\n",
    "# Localizar los tweets que contengan la frase, y de ellos tomar los usuarios, para agregarlos a los que ya\n",
    "# estaban listados, siempre y cuando todos los tweets del usuario contengan la frase\n",
    "\n",
    "usuarios_frags_ahorcarme <- obtenerUsuariosRepetitivos(publicaciones_ahorcarme, frags_frase)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro son fragmentos de una canción, en los tweets con la palabra clave \"colgarme\"\n",
    "\n",
    "Los fragmentos son los siguientes:\n",
    "\n",
    "<blockquote>\n",
    "    <ul>\n",
    "        <li> Niña, dame una pestaña de tus ojos para colgarme de amor por ti </li>\n",
    "        <li> Colgarme de cualquiera que le gusta trasnochar </li>\n",
    "    </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fragmentos\n",
    "frags_frase = c(\n",
    "    \"Niña, dame una pestaña de tus ojos para colgarme de amor por ti\",\n",
    "    \"Colgarme de cualquiera que le gusta trasnochar\"\n",
    ")\n",
    "# Localizar los tweets que contengan la frase, y de ellos tomar los usuarios, para agregarlos a los que ya\n",
    "# estaban listados.\n",
    "\n",
    "usuarios_frags_colgarme <- obtenerUsuariosRepetitivos(publicaciones_colgarme, frags_frase)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igualmente, se removerá cualquier uso de la llamada en el contexto de una conversación telefónica.\n",
    "\n",
    "Por su parte, otros usos de la palabra que se refieran a una acción como \"depender de\" o \"aprovecharse de\" podrían requerir de otro tipo de servicios para ser procesados.\n",
    "\n",
    "En [este notebook](./filtrado_tweets_ahorcarme.ipynb) estaré trabajando en otros usos de la palabra a través de los servicios que ofrece Microsoft Azure. Indagaré en el uso de los servicios cognitivos o las integraciones con OpenAI para proveer un filtro de las publicaciones con un procesamiento del lenguaje más intuitivo y preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "raiz_verbo_aparece <- function(texto, raices_a_comparar, language) {\n",
    "\n",
    "    palabras <- unlist(strsplit(texto, \" \"))\n",
    "    raices_palabras <- wordStem(palabras, language = language)\n",
    "    \n",
    "    for (raiz_palabra in raices_palabras) {\n",
    "        \n",
    "        for (raiz_verbo in raices_a_comparar) {\n",
    "            \n",
    "            if ( grepl(raiz_verbo, raiz_palabra, ignore.case = TRUE) ) {\n",
    "                return(TRUE)\n",
    "            }\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    return(FALSE)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Usando el paquete tm, se buscarán los tweets que contengan alguna conjugación de los verbos indicados\n",
    "\n",
    "excluir_tweets_segun_palabras <- function(dataframe, palabras, language) {\n",
    "\n",
    "    # Se obtienen las raíces de las palabras\n",
    "    raices_palabras <- wordStem(palabras, language = language)\n",
    "\n",
    "    # Se obtienen los tweets que no contengan ninguna de las raíces de las palabras (i.e., el verbo no aparece\n",
    "    # en ninguna conjugación)\n",
    "    tweets_sin_palabras <- dataframe %>%\n",
    "        mutate(\n",
    "            contiene_raices_palabras = sapply(Content, raiz_verbo_aparece, raices_palabras, language)\n",
    "        ) %>%\n",
    "        filter(contiene_raices_palabras == FALSE) %>%\n",
    "        select(-contiene_raices_palabras) # Se elimina la columna auxiliar\n",
    "\n",
    "    return(tweets_sin_palabras)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"llam\"    \"marc\"    \"respond\" \"contest\"\n"
     ]
    }
   ],
   "source": [
    "# No quitamos al usuario completamente porque el uso de la palabra \"colgar\" en una llamada no le excluye de usarla con\n",
    "# intenciones autolesivas, por lo que nos limitamos a excluir esas publicaciones\n",
    "\n",
    "palabras_contexto_telefonico <- c(\n",
    "    \"llamar\",\n",
    "    \"marcar\",\n",
    "    \"responder\",\n",
    "    \"contestar\"\n",
    ")\n",
    "\n",
    "# Demostrando el uso del paquete tm\n",
    "raices_palabras_contexto_telefonico <- wordStem(palabras_contexto_telefonico, language = \"spanish\")\n",
    "print(raices_palabras_contexto_telefonico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Eliminamos los tweets que contengan alguna conjugación de los verbos que indican que se habla de una llamada\n",
    "\n",
    "tweets_colgarme_limpios <- excluir_tweets_segun_palabras(\n",
    "    publicaciones_colgarme,\n",
    "    palabras_contexto_telefonico,\n",
    "    \"spanish\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Escribir tweets para no depender de la sesión de R\n",
    "escribir_dataframe(tweets_colgarme_limpios, \"./datos_limpios/datos_por_revisar/tweets_colgarme_limpios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Escribir los mismos tweets, pero extrayendo aquellos cuyos usuarios aparecen con frecuencia\n",
    "\n",
    "write.table(\n",
    "    obtener_publicaciones(tweets_colgarme_limpios, 5),\n",
    "    file = \"./datos_limpios/datos_por_revisar/tweets_colgarme_radicados_5_ocurrencias.csv\",\n",
    "    row.names = FALSE,\n",
    "    col.names = TRUE,\n",
    "    quote = TRUE,\n",
    "    sep = \",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Agregar los usuarios a la lista de usuarios\n",
    "\n",
    "lista_negra <- juntar_usuarios(\n",
    "    c(\n",
    "        lista_negra,\n",
    "        usuarios_frags_ahorcarme,\n",
    "        usuarios_frags_colgarme\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Escribimos las listas de usuarios para no depender de la sesión de R\n",
    "writeLines(usuarios_frags_ahorcarme, \"./datos_limpios/datos_por_revisar/usuarios_frag_ahorcarme.txt\")\n",
    "writeLines(usuarios_frags_colgarme, \"./datos_limpios/datos_por_revisar/usuarios_frag_colgarme.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Escribir la lista negra en un archivo\n",
    "writeLines(\n",
    "    lista_negra,\n",
    "    file = \"./datos_limpios/datos_por_revisar/lista_negra.txt\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aquí, una vez que hallamos revisado la lista negra de usuarios, vamos a limpiar los conjuntos de datos para obtener únicamente la información útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Excluir a estos usuarios de los datasets, pero a partir de la lista negra de usuarios ya revisada\n",
    "\n",
    "# Leer lista\n",
    "lista_negra_revisada <- readLines(\"./datos_limpios/lista_negra_revisada.txt\", encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Reescribir lista negra, para obtener sólo valores únicos\n",
    "lista_negra_revisada <- unique(lista_negra_revisada) %>% sort()\n",
    "writeLines(lista_negra_revisada, \"./datos_limpios/lista_negra_revisada.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "retirar_tweets_usuarios <~ function(dataframe, usuarios) {\n",
    "    return (\n",
    "        dataframe %>%\n",
    "            filter(!User %in% usuarios)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Ahorcarme\n",
    "publicaciones_ahorcarme <- retirar_tweets_usuarios(publicaciones_ahorcarme, lista_negra_revisada)\n",
    "\n",
    "# Colgarme\n",
    "publicaciones_colgarme <- retirar_tweets_usuarios(tweets_colgarme_limpios, lista_negra_revisada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos los tweets en un archivo\n",
    "\n",
    "# Ahorcarme\n",
    "escribir_dataframe(publicaciones_ahorcarme, \"./datos_limpios/ahorcarme_filtered.csv\")\n",
    "\n",
    "# Colgarme\n",
    "escribir_dataframe(publicaciones_colgarme, \"./datos_limpios/colgarme_filtered.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
